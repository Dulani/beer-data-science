---
title: Data Science Musings on Beer
author:
  name: Amanda Dobbyn
date: "`r format(Sys.time(), '%B %d, %Y')`"
output: 
  html_document:
    keep_md: true
    toc: false
    theme: yeti
  github_document:
    toc: true
---



```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(fig.width=12, fig.height=8) 
options(knitr.table.format = 'markdown')

source("./cluster.R")
source("./plot.R")
source("./get_ingredient_levels.R")
library(knitr)
```

* Main question
    * Are there natural clusters in beer that are defined by styles? Or are style boundaries more or less arbitrary?
      * Unsupervised (k-means) clustering based on 
        * ABV (alcohol by volume), IBU (international bitterness units), SRM (measure of color)
        * Style centers defined by mean of ABV, IBU, and SRM
      * Neural net 
        * Can we predict a beer's style based on a number of attributes we 
      
* Answer
    * Looks more or less fluid: there aren't really pockets centered around a style

![](./taps.jpg)

### General Workflow

* Hit the BreweryDB API to iteratively pull in all beers and their ingredients
    * Dump them into a MySQL database along with other things we'd want like breweries and glassware
* Unnest the JSON response including all the ingredients columns
* Create a `style_collapsed` column
    * Look for main style strings like `Pale Ale` and chop out everything else
    * Further collpase styles that are similar like Hefeweizen and Wit into Wheat
* Unnest the ingredients `hops` and `malts` into a sparse matrix
    * Individual ingredients as columns, beers as rows; cell gets a 1 if ingredient is present and 0 otherwise 

* Data courtesy of [BreweryDB](http://www.brewerydb.com/developers)
    * Special thanks to [Kris Kroksi](https://kro.ski/) for data ideation and beer




**Getting Beer**



* The BreweryDB API returns a certain number of results per page; if we want 
* So, we hit the BreweryDB API and ask for `1:number_of_pages`
    * We can change `number_of_pages` to, e.g., 3 if we only want the first 3 pages
    * If there's only one page (as is the case for the glassware endpoing), numberOfPages won't be returned, so in this case we set number_of_pages to 1
* The `addition` parameter can be an empty string if nothing else is needed

```{r, eval = FALSE, echo=TRUE}

base_url <- "http://api.brewerydb.com/v2"
key_preface <- "/?key="

paginated_request <- function(ep, addition) {    
  full_request <- NULL
  first_page <- fromJSON(paste0(base_url, "/", ep, "/", key_preface, key
                                , "&p=1"))
  number_of_pages <- ifelse(!(is.null(first_page$numberOfPages)), 
                            first_page$numberOfPages, 1)      

    for (page in 1:number_of_pages) {                               
    this_request <- fromJSON(paste0(base_url, "/", ep, "/", key_preface, key
                                    , "&p=", page, addition),
                             flatten = TRUE) 
    this_req_unnested <- unnest_it(this_request)    #  <- request unnested here
    print(this_req_unnested$currentPage)
    full_request <- bind_rows(full_request, this_req_unnested[["data"]])
  }
  full_request
} 

all_beer_raw <- paginated_request("beers", "&withIngredients=Y")
```



* Function for unnesting JSON used inside `paginated_request()` below
    + Takes the column named `name` nested within a column in the data portion of the response
        + If the `name` column doesn't exist, it takes the first nested column
* We use something similar to unnest ingredient like all of a beer's hops and malts into a long string contained in `hops_name` and `malt_name`

```{r, eval=FALSE, echo=TRUE}
unnest_it <- function(df) {
  unnested <- df
  for(col in seq_along(df[["data"]])) {
    if(! is.null(ncol(df[["data"]][[col]]))) {
      if(! is.null(df[["data"]][[col]][["name"]])) {
        unnested[["data"]][[col]] <- df[["data"]][[col]][["name"]]
      } else {
        unnested[["data"]][[col]] <- df[["data"]][[col]][[1]]
      }
    }
  }
  unnested
}
```



**Collapse Styles**

* Save the most popular styles in `keywords`
* Loop through each keyword
    * For each beer, `grep` through its style column to see if it contains any one of these keywords
    * If it does, give it that keyword in a new column `style_collapsed`
* If a beer's name matches multiple keywords, e.g., American Double India Pale Ale would match Double India Pale Ale, India Pale Ale, and Pale Ale, its `style_collapsed` is the **last** of those that appear in keywords 
    * This is why keywords are intentionally ordered from most general to most specific
    * So in the case of an case of American Double India Pale Ale: since Double India Pale Ale appears in `keywords` after India Pale Ale and Pale Ale, an American Double India Pale Ale would get a `style_collapsed` of Double India Pale Ale
* If no keyword is contained in `style`, `style_collapsed` is just whatever's in `style`; in other words, it doesn't get collpsed into a bigger bucket
    * This isn't a huge problem because we'll pare down to just the most popular styles later, however we could think about creating a catchall "Other" level for `style_collapsed`

```{r, eval=FALSE, echo=TRUE}

collapse_styles <- function(df) {
  keywords <- c("Lager", "Pale Ale", "India Pale Ale", "Double India Pale Ale", "India Pale Lager", "Hefeweizen", "Barrel-Aged","Wheat", "Pilsner", "Pilsener", "Amber", "Golden", "Blonde", "Brown", "Black", "Stout", "Porter", "Red", "Sour", "KÃ¶lsch", "Tripel", "Bitter", "Saison", "Strong Ale", "Barley Wine", "Dubbel", "Altbier")
  
  for (beer in 1:nrow(df)) {
    if (grepl(paste(keywords, collapse="|"), df$style[beer])) {    
      for (keyword in keywords) {         
        if(grepl(keyword, df$style[beer]) == TRUE) {
          df$style_collapsed[beer] <- keyword    
        }                         
      } 
    } else {
      df$style_collapsed[beer] <- as.character(df$style[beer])       
    }
    print(df$style_collapsed[beer])
  }
  return(df)
}

```

* Then we collapse further; right now we just combine all wheaty bears into Wheat by `fct_collapse`ing those levels



**Split out Ingredients**

* When we unnested ingredients, we just concatenated all of the ingredients for a given beer into a long string
* If we want, we can split out the ingredients that were concatenated in `<ingredient>_name` with this `split_ingredients` function
* This takes a vector of `ingredients_to_split`, so e.g. `c("hops_name", "malt_name")` and creates one column for each type of ingredient (`hops_name_1`, `hops_name_2`, etc.)

* We `str_split` on the ingredient and get a list back
* We find the max number of instances of an ingredient per beer, which will be the number of columns we're adding
* For each new column we need, we create it, initialize it with NAs, and name it
* Then for each element in our list of split up ingredients, if it exists, we add it to the correct column in our df

```{r, eval=FALSE, echo=TRUE}
split_ingredients <- function(df, ingredients_to_split) {
  
  ncol_df <- ncol(df)
  
  for (ingredient in ingredients_to_split) {

    ingredient_split <- str_split(df[[ingredient]], ", ")    
    num_new_cols <- max(lengths(ingredient_split))    
  
    for (num in 1:num_new_cols) {
      
      this_col <- ncol_df + 1         
      
      df[, this_col] <- NA
      names(df)[this_col] <- paste0(ingredient, "_", num)
      ncol_df <- ncol(df)             
      for (row in seq_along(ingredient_split)) {          
        if (!is.null(ingredient_split[[row]][num])) {        
          df[row, this_col] <- ingredient_split[[row]][num]
        }
      }
      df[[names(df)[this_col]]] <- factor(df[[names(df)[this_col]]])
    }
    
    ncol_df <- ncol(df)
  }
  return(df)
}
```



Head of the clustering data
```{r}
kable(beer_for_clustering[1:20, ])
```


**Find the Most Popualar Styles**

```{r, eval=FALSE, echo=TRUE}
# Pare down to only cases where style is not NA
beer_dat_pared <- beer_dat[complete.cases(beer_dat$style), ]

# Arrange beer dat by style popularity
style_popularity <- beer_dat_pared %>% 
  group_by(style) %>% 
  count() %>% 
  arrange(desc(n))
style_popularity

# Add a column that scales popularity
style_popularity <- bind_cols(style_popularity, 
                               n_scaled = as.vector(scale(style_popularity$n)))

# Find styles that are above a z-score of 0
popular_styles <- style_popularity %>% 
  filter(n_scaled > 0)

# Pare dat down to only beers that fall into those styles
popular_beer_dat <- beer_dat_pared %>% 
  filter(
    style %in% popular_styles$style
  ) %>% 
  droplevels() %>% 
  as_tibble() 
nrow(popular_beer_dat)

# Find the centers (mean abv, ibu, srm) of the most popular styles
style_centers <- popular_beer_dat %>% 
  group_by(style_collapsed) %>% 
  add_count() %>% 
  summarise(
    mean_abv = mean(abv, na.rm = TRUE),
    mean_ibu = mean(ibu, na.rm = TRUE), 
    mean_srm = mean(srm, na.rm = TRUE),
    n = median(n, na.rm = TRUE)          # Median here only for summarise. Should be just the same as n
  ) %>% 
  arrange(desc(n)) %>% 
  drop_na() %>% 
  droplevels()
```


Compare popular styles      

```{r}
kable(style_centers)
```


## Unsupervised Clustering 
* Pare down to beers that have ABV, IBU, and SRM
* K-means cluster beers based on these predictors


**Do Clustering**

* Use only the top beer styles
* Split off the predictors, ABV, IBU, and SRM
* Take out NAs, and scale the data
    * NB: There are not not very many beers have SRM so we may not want to omit based on it
* Take out some outliers
  * Beers have to have an ABV between 3 and 20 and an IBU less than 200
  
```{r, eval=FALSE, echo=TRUE}
beer_for_clustering <- popular_beer_dat %>% 
  select(name, style, styleId, style_collapsed,
         abv, ibu, srm) %>%       
  na.omit() %>% 
  filter(
    abv < 20 & abv > 3
  ) %>%
  filter(
    ibu < 200
  )

beer_for_clustering_predictors <- beer_for_clustering %>% 
  select(abv, ibu, srm) %>%
  rename(
    abv_scaled = abv,
    ibu_scaled = ibu,
    srm_scaled = srm
    ) %>% scale() %>% 
  as_tibble()
```

And do the clustering

```{r, eval=FALSE, echo=TRUE}
set.seed(9)
clustered_beer_out <- kmeans(x = beer_for_clustering_predictors, centers = 10, trace = TRUE)

clustered_beer <- as_tibble(data.frame(cluster_assignment = factor(clustered_beer_out$cluster), 
                            beer_for_clustering_outcome, beer_for_clustering_predictors,
                            beer_for_clustering %>% select(abv, ibu, srm)))

```


A table of cluster counts broken down by style
```{r}
kable(cluster_table_counts)
```


A couple plots of the same thing

```{r, echo=TRUE}
clustered_beer_plot_abv_ibu <- ggplot(data = clustered_beer, aes(x = abv, y = ibu, colour = cluster_assignment)) + 
  geom_jitter() + theme_minimal()  +
  ggtitle("k-Means Clustering of Beer by ABV, IBU, SRM") +
  labs(x = "ABV", y = "IBU") +
  labs(colour = "Cluster Assignment")
clustered_beer_plot_abv_ibu

clustered_beer_plot_abv_srm <- ggplot(data = clustered_beer, aes(x = abv, y = srm, colour = cluster_assignment)) + 
  geom_jitter() + theme_minimal()  +
  ggtitle("k-Means Clustering of Beer by ABV, IBU, SRM") +
  labs(x = "ABV", y = "SRM") +
  labs(colour = "Cluster Assignment")
clustered_beer_plot_abv_srm
```


### Now add in the style centers (means) for collapsed styles

```{r, echo=TRUE}
library(ggrepel)
abv_ibu_clusters_vs_style_centers <- ggplot() +   
  geom_point(data = clustered_beer, 
             aes(x = abv, y = ibu, colour = cluster_assignment), alpha = 0.5) +
  geom_point(data = style_centers,
             aes(mean_abv, mean_ibu), colour = "black") +
  geom_text_repel(data = style_centers, aes(mean_abv, mean_ibu, label = style_collapsed), 
                  box.padding = unit(0.45, "lines"),
                  family = "Calibri",
                  label.size = 0.3) +
  ggtitle("Popular Styles vs. k-Means Clustering of Beer by ABV, IBU, SRM") +
  labs(x = "ABV", y = "IBU") +
  labs(colour = "Cluster Assignment") +
  theme_bw()
abv_ibu_clusters_vs_style_centers
```




# Neural Net

* Can ABV, IBU, and SRM be used in a neural net to predict `style` or `style_collapsed`?

```{r, warning=FALSE, echo=TRUE, eval=FALSE}

library(neuralnet)
library(nnet)
library(caret)

# split into training and test sets
beer_train <- sample_n(popular_beer_dat, 3000)
beer_test <- popular_beer_dat %>% filter(! (id %in% beer_train$id))


beer_necessities_train <- sample_n(beer_necessities, 21102)
beer_necessities_test <- beer_necessities %>% filter(! (id %in% beer_necessities_train$id))



# build multinomail neural net
nn_mod <- multinom(style ~ abv + srm + ibu, 
                   data = beer_train, maxit=500, trace=T)
nn_mod

# same model on style_collapsed
nn_collapsed <- multinom(style_collapsed ~ abv + srm + ibu, 
                   data = beer_necessities_train, maxit=500, trace=T)
nn_collapsed


# which variables are the most important in the neural net?
most_important_vars <- varImp(nn_mod)
# most_important_vars

# which variables are the most important in the neural net?
most_important_vars_collapsed <- varImp(nn_collapsed)
# most_important_vars_collapsed

```


Accuracy 
```{r, echo=TRUE, eval=FALSE}

# how accurate is the model?
# preds
nn_preds <- predict(nn_mod, type="class", newdata = beer_test)
nn_preds_collapsed <- predict(nn_collapsed, type="class", newdata = beer_necessities_test)


# accuracy
postResample(beer_test$style, nn_preds)
postResample(beer_necessities$style_collapsed, nn_preds_collapsed)

```


### Ingredients



```{r, echo=TRUE, messages=FALSE, warning=FALSE}
get_last_ing_name_col <- function(df) {
  for (col in names(df)) {
    if (grepl(paste(ingredient_want, "_name_", sep = ""), col) == TRUE) {
      name_last_ing_col <- col
    }
  }
  return(name_last_ing_col)
}

```


**Gather some global variables**

* We set `ingredient_want` at the outset: this can be `hops`, `malt`, or other ingredients like `yeast` if we pull that in
* Once ingredients have been split out from the concatenated string into columns like `malt_name_1`, `malt_name_2`, etc., we need to find the range of these columns; there will be a different number of malt columns than hops columns, for instance
    * The first one will be `<ingredient>_name_1` 
        * From this we can find the index of this column 
    * We get the name of last one with the `get_last_ing_name_col` function
* Then we save a vector of all the ingredient column names in `ingredient_colnames`
    * We make this a global variable because it will stay constant even if the indices change
    
* `to_keep_col_names` is a vector of all non-ingredient column names

```{r, echo=TRUE, eval=TRUE}
# Data
clustered_beer_necessities <- clustered_beer %>% 
  inner_join(beer_necessities)

# Ingredient we want to spread out
ingredient_want <- "hops"

# First ingredient
first_ingredient_name <- paste(ingredient_want, "_name_1", sep="")
first_ingredient_index <- which(colnames(clustered_beer_necessities)==first_ingredient_name)

# Last ingredient
last_ingredient_name <- get_last_ing_name_col(clustered_beer_necessities)
last_ingredient_index <- which(colnames(clustered_beer_necessities)==last_ingredient_name)

# Vector of all the ingredient column names
ingredient_colnames <- names(clustered_beer_necessities)[first_ingredient_index:last_ingredient_index]

# Non-ingredient column names we want to keep
to_keep_col_names <- c("cluster_assignment", "name", "abv", "ibu", "srm", "style", "style_collapsed")

```

**Gather**

* Inside `gather_ingredients` we:
    * Take out superflous column names that are not in `to_keep_col_names` or one of the ingredient columns
    * Find what the new ingredient column indices are, since they'll have changed after we pared down
    * Actually do the gathering: lump all of the ingredient columns (e.g., `hops_name_1`) into one long column, `ing_keys` and all the actual ingredient names (e.g., Cascade) into `ing_names`
    

```{r, echo=TRUE, eval=TRUE, messages=FALSE, warning=FALSE}
gather_ingredients <- function(df, cols_to_gather) {
  to_keep_indices <- which(colnames(df) %in% to_keep_col_names)
  
  selected_df <- df[, c(to_keep_indices, first_ingredient_index:last_ingredient_index)]
  
  new_ing_indices <- which(colnames(selected_df) %in% cols_to_gather)    
  
  df_gathered <- selected_df %>%
    gather_(
      key_col = "ing_keys",
      value_col = "ing_names",
      gather_cols = colnames(selected_df)[new_ing_indices]
    ) %>%
    mutate(
      count = 1
    )
  df_gathered
}
beer_gathered <- gather_ingredients(clustered_beer_necessities, ingredient_colnames)  
```

* Get a vector of all ingredient levels and take out the one that's an empty string
* We'll use this vector of ingredient levels in `select_spread_cols()` below
```{r, eval=TRUE, echo=TRUE}
beer_gathered$ing_names <- factor(beer_gathered$ing_names)
ingredient_levels <- levels(beer_gathered$ing_names)

to_keep_levels <- !(c(1:length(ingredient_levels)) %in% which(ingredient_levels == ""))
ingredient_levels <- ingredient_levels[to_keep_levels]

beer_gathered$ing_names <- as.character(beer_gathered$ing_names)
```


**Spread**
* We take what was previously the `value` in our gathered dataframe, the actual ingredient names (Cascade, Centennial) and make that our `key`; it'll form the new column names
    * The new `value` is `value` is count; it'll populate the row cells
        * If a given row has a certain ingredient, it gets a 1 in the corresponding cell, an NA otherwise
* We add a unique idenfitier for each row with `row`, which we'll drop later (see [Hadley's SO comment](https://stackoverflow.com/questions/25960394/unexpected-behavior-with-tidyr))

```{r, echo=TRUE, eval=TRUE, warning=FALSE}
spread_ingredients <- function(df) {
  df_spread <- df %>% 
    mutate(
      row = 1:nrow(df)        
    ) %>%                   
    spread(
      key = ing_names,
      value = count
    ) 
  return(df_spread)
}

beer_spread <- spread_ingredients(beer_gathered)



select_spread_cols <- function(df) {
  to_keep_col_indices <- which(colnames(df) %in% to_keep_col_names)
  to_keep_ingredient_indices <- which(colnames(df) %in% ingredient_levels)
  
  to_keep_inds_all <- c(to_keep_col_indices, to_keep_ingredient_indices)

  new_df <- df %>% 
    select_(
      .dots = to_keep_inds_all
      )
  return(new_df)
}
beer_spread_selected <- select_spread_cols(beer_spread)



# take out all rows that have no ingredients specified at all
inds_to_remove <- apply(beer_spread_selected[, first_ingredient_index:last_ingredient_index], 
             1, function(x) all(is.na(x)))
beer_spread_no_na <- beer_spread_selected[ !inds_to_remove, ]


# Can specify multiple groupers
get_ingredients_per_grouper <- function(df, grouper) {
  df_grouped <- df %>%
    ungroup() %>% 
    group_by_(grouper)
    
  not_for_summing <- which(colnames(df_grouped) %in% to_keep_col_names)
  max_not_for_summing <- max(not_for_summing)   # find the first ingredient column we want to sum over
  
  per_grouper <- df_grouped %>% 
    select(-c(abv, ibu, srm)) %>% 
    summarise_if(
      is.numeric,
      sum, na.rm = TRUE
    ) %>%
    mutate(
      total = rowSums(.[(max_not_for_summing + 1):ncol(.)], na.rm = TRUE)    
    )
  
  return(per_grouper)
}
ingredients_per_beer <- get_ingredients_per_grouper(beer_spread_selected, c("name", "style_collapsed"))

ingredients_per_style_collapsed <- get_ingredients_per_grouper(beer_spread_selected, "style_collapsed")

```


Now we're left with something of a sparse matrix of all the ingredients compared to all the beers
```{r}
kable(head(ingredients_per_beer))
```

Per `style_collapsed`
```{r}
kable(ingredients_per_style_collapsed[1:20, ])
```


<!-- All hops types -->

<!-- ```{r} -->
<!-- kable(all_hops_levels) -->
<!-- ``` -->

<!-- All malt types -->
<!-- ```{r} -->
<!-- kable(all_malt_levels) -->
<!-- ``` -->





### Updated neural net with ingredients



